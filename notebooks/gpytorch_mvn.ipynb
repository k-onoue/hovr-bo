{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultivariateNormal(loc: torch.Size([3, 1]), covariance_matrix: torch.Size([3, 3, 3]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpytorch.distributions import MultivariateNormal\n",
    "import torch\n",
    "\n",
    "# Define mean and covariance\n",
    "mean = torch.zeros(3).reshape(-1, 1)\n",
    "covariance = torch.tensor([[1.0, 0.5, 0.2],\n",
    "                           [0.5, 1.0, 0.3],\n",
    "                           [0.2, 0.3, 1.0]])\n",
    "\n",
    "# Create MultivariateNormal\n",
    "mvn = MultivariateNormal(mean, covariance)\n",
    "mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1) must match the existing size (3) at non-singleton dimension 2.  Target sizes: [3, 1, 1].  Tensor sizes: [3, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmvn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ws/hovr-bo/.venv_hovr/lib/python3.10/site-packages/gpytorch/distributions/multivariate_normal.py:221\u001b[0m, in \u001b[0;36mMultivariateNormal.rsample\u001b[0;34m(self, sample_shape, base_samples)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrsample\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_shape: torch\u001b[38;5;241m.\u001b[39mSize \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize(), base_samples: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m    Generates a `sample_shape` shaped reparameterized sample or `sample_shape`\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    shaped batch of reparameterized samples if the distribution parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m    :return: A `*sample_shape x *batch_shape x N` tensor of i.i.d. reparameterized samples.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m     covar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_covariance_matrix\u001b[49m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m base_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;66;03m# Create some samples\u001b[39;00m\n\u001b[1;32m    224\u001b[0m         num_samples \u001b[38;5;241m=\u001b[39m sample_shape\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/ws/hovr-bo/.venv_hovr/lib/python3.10/site-packages/torch/distributions/utils.py:149\u001b[0m, in \u001b[0;36mlazy_property.__get__\u001b[0;34m(self, instance, obj_type)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _lazy_property_and_property(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 149\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28msetattr\u001b[39m(instance, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, value)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m~/ws/hovr-bo/.venv_hovr/lib/python3.10/site-packages/gpytorch/distributions/multivariate_normal.py:163\u001b[0m, in \u001b[0;36mMultivariateNormal.lazy_covariance_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_covar\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m to_linear_operator(\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovariance_matrix\u001b[49m)\n",
      "File \u001b[0;32m~/ws/hovr-bo/.venv_hovr/lib/python3.10/site-packages/torch/distributions/utils.py:149\u001b[0m, in \u001b[0;36mlazy_property.__get__\u001b[0;34m(self, instance, obj_type)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _lazy_property_and_property(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 149\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28msetattr\u001b[39m(instance, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, value)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m~/ws/hovr-bo/.venv_hovr/lib/python3.10/site-packages/torch/distributions/multivariate_normal.py:218\u001b[0m, in \u001b[0;36mMultivariateNormal.covariance_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;129m@lazy_property\u001b[39m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcovariance_matrix\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unbroadcasted_scale_tril\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unbroadcasted_scale_tril\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmT\u001b[49m\n\u001b[0;32m--> 218\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (3) at non-singleton dimension 2.  Target sizes: [3, 1, 1].  Tensor sizes: [3, 3]"
     ]
    }
   ],
   "source": [
    "mvn.rsample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " tensor([[ 0.8380, -0.7193, -0.4033],\n",
      "        [-0.5966,  0.1820, -0.8567],\n",
      "        [ 1.1006, -1.0712,  0.1227],\n",
      "        [-0.5663,  0.3731, -0.8920]])\n",
      "Output (predictive distribution):\n",
      " tensor([[1.0463],\n",
      "        [0.7578],\n",
      "        [0.8796],\n",
      "        [0.8038]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class MockDistribution:\n",
    "    def __init__(self, mean, cov):\n",
    "        self.mean = mean  # Mean of the distribution\n",
    "        self.cov = cov    # Covariance of the distribution\n",
    "    \n",
    "    def sample(self):\n",
    "        # Simulate sampling from the distribution\n",
    "        return torch.randn_like(self.mean) * torch.sqrt(self.cov) + self.mean\n",
    "\n",
    "class RegressionExample(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(RegressionExample, self).__init__()\n",
    "        # Define mock posterior for weights\n",
    "        self.weight_mean = torch.randn(out_features, in_features)\n",
    "        self.weight_cov = torch.abs(torch.randn(out_features, in_features))  # Variance must be non-negative\n",
    "        self.W_dist = MockDistribution(self.weight_mean, self.weight_cov)\n",
    "        \n",
    "        # Define mock posterior for noise\n",
    "        self.noise_mean = torch.zeros(out_features)\n",
    "        self.noise_logdiag = torch.randn(out_features) * np.log(0.1)\n",
    "        self.noise_scale = torch.exp(self.noise_logdiag)\n",
    "        self.noise_dist = MockDistribution(self.noise_mean, self.noise_scale)\n",
    "\n",
    "    def W(self):\n",
    "        # Sample weights from the posterior\n",
    "        return self.W_dist.sample()\n",
    "\n",
    "    def noise(self):\n",
    "        # Sample noise from the posterior\n",
    "        return self.noise_dist.sample()\n",
    "\n",
    "    def predictive(self, x):\n",
    "        # Compute predictive distribution\n",
    "        return (self.W() @ x[..., None]).squeeze(-1) + self.noise()\n",
    "\n",
    "# Example usage\n",
    "torch.manual_seed(0)  # For reproducibility\n",
    "\n",
    "# Initialize model\n",
    "model = RegressionExample(in_features=3, out_features=1)\n",
    "\n",
    "# Create some random input data\n",
    "x = torch.randn(4, 3)  # Batch of 4, 3 input features\n",
    "\n",
    "# Get predictive distribution\n",
    "output = model.predictive(x)\n",
    "print(\"Input:\\n\", x)\n",
    "print(\"Output (predictive distribution):\\n\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.5000, 0.2000],\n",
       "        [0.5000, 1.0000, 0.3000],\n",
       "        [0.2000, 0.3000, 1.0000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariance.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.5000, 0.2000],\n",
       "        [0.5000, 1.0000, 0.3000],\n",
       "        [0.2000, 0.3000, 1.0000]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariance.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input matrix (x):\n",
      " tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "Weights matrix (W):\n",
      " tensor([[ 0.5000, -0.2000,  0.1000],\n",
      "        [ 0.4000,  0.7000, -0.3000]])\n",
      "Noise vector:\n",
      " tensor([ 0.1000, -0.2000])\n",
      "Output:\n",
      " tensor([[0.5000, 0.7000],\n",
      "        [1.7000, 3.1000],\n",
      "        [2.9000, 5.5000],\n",
      "        [4.1000, 7.9000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define dimensions\n",
    "batch_size = 4\n",
    "in_features = 3\n",
    "out_features = 2\n",
    "\n",
    "# Random weights matrix (out_features x in_features)\n",
    "W = torch.tensor([[0.5, -0.2, 0.1],\n",
    "                  [0.4, 0.7, -0.3]])\n",
    "\n",
    "# Random input matrix (batch_size x in_features)\n",
    "x = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                  [4.0, 5.0, 6.0],\n",
    "                  [7.0, 8.0, 9.0],\n",
    "                  [10.0, 11.0, 12.0]])\n",
    "\n",
    "# Random noise vector (out_features)\n",
    "noise = torch.tensor([0.1, -0.2])\n",
    "\n",
    "# Step-by-step computation\n",
    "# 1. Reshape x to (batch_size, in_features, 1)\n",
    "x_column = x[..., None]  # Shape: (4, 3, 1)\n",
    "\n",
    "# 2. Matrix multiplication\n",
    "Wx = torch.matmul(W, x_column)  # Shape: (4, 2, 1)\n",
    "\n",
    "# 3. Squeeze the last dimension\n",
    "Wx_squeezed = Wx.squeeze(-1)  # Shape: (4, 2)\n",
    "\n",
    "# 4. Add noise\n",
    "output = Wx_squeezed + noise  # Shape: (4, 2)\n",
    "\n",
    "# Print results\n",
    "print(\"Input matrix (x):\\n\", x)\n",
    "print(\"Weights matrix (W):\\n\", W)\n",
    "print(\"Noise vector:\\n\", noise)\n",
    "print(\"Output:\\n\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_hovr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
